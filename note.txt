What is AI?

We are going to be building machines and softwares that does something? What is that something we are going to achieve? What is our goal? What does it really mean to build artificial intelligence. 

Well, there are multiple schools of thoughts on this:

One school of thought is we should be building machines that think like people. Intelligence is about thinking, and this is artificial. Well, what is natural intelligence, I guess that’s us. So we want to build machines that somehow go through the thinking processes that people do. There is actually a science that studies this. It’s not really AI anymore. It’s some mix of cognitive science and computational neural science really trying to understand the human brain. 

Another thing the people at times thought was the AI should be, is we should build machines act like people. We should say: who cares how they think - they can think some strange silicon way - but the action, the behaviour has to be like what we know from people. This is actually a very early definition. Really all you can do is check the behaviour - is the behaviour like an intelligent human. This led to things like turing test where you put a human on one chat channel and a robot on the other. Then the interrogator tries to chat with both of them and say that one was robot and this one was a human. This was a real good idea. You can check anything - do they have hobbies and likes and dislikes etc. The problem was, in turing test, in ordered to do really well, you don’t concentrate on programming intelligence, but concentrate on things like don’t spell too well - because humans don’t do that. Then you build some machine that do typos. Then wait a minute, if I get asked about square root of 35 I better not have an answer! So basically you will go and build a machine with a goal to mimic humans than make it really intelligent. On the other hand you have to be sure that you really have a favourite movies or actor because interrogators always ask that. 

So this is thinking like people and acting like people. The realisation this wasn’t going anywhere in terms of making machines that are useful to the industry.

So may it is not about mimicking people - that is good for fun. May be we should do something else. We should build machines that think rationally. Whatever thought processes that they have, should be correct. What does it mean to have a correct thought process? It’s kind of a hard to tell thing. This is how you should think in order to not make a mistake. This still shows up in various areas of AI. By and large this wasn’t the winner. The reason why this wasn’t the winner is because our ability to write down steps to achieve a goal turned out to be relative fragile. For example, let’s say you know how to ride a cycle, there is a set of processes to be followed. But if you were to write down or tell something the exact thought process that is going on through mind, it would be difficult. 

So that brought us to the thought that AI is not about thinking, but it’s all about acting rationally. So AI is science of making machines that act rationally. What that means is we only care about what they do, and our requirement on what they do is they achieve the goal optimally. When you look at this you may think may be we shouldn’t build machines that get angry. May it is a very good idea. Skynet got little angry and we know what happened. Well rational doesn’t mean that. The word rational has a very technical meaning in our context. It mean that you maximally achieve your predefined goals. So the input to an AI machine is a goal and the rationality means you achieve this in the best possible way. Rationally only matters what you do, it doesn’t matter the thought process you go through. If you have a robot vacuum cleaner that makes up some grid in the ground and cleans up the dirt or it sits in the corner and thinks for five minutes where should I start and cleans up the dirt - fine - they are equally rational for that task in that context.




